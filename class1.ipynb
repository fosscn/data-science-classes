{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe59bc8",
   "metadata": {},
   "source": [
    "# Data Science - Class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f425c9",
   "metadata": {},
   "source": [
    "### Exercise 1 - Data Collection\n",
    "Use BeautifulSoup (Python) library to perform **web scraping**. Use the site: https://www.ayush.nz/technology\n",
    "\n",
    "* requests.get(url, headers=headers) â€“ Fetches the HTML content of a webpage. \n",
    "    * Example: response = requests.get(\"https://example.com\") \n",
    "* BeautifulSoup(html, 'html.parser') â€“ Parses HTML content. \n",
    "    * Example: soup = BeautifulSoup(response.text, 'html.parser') \n",
    "* soup.select('div.article-link') â€“ Selects elements using CSS selectors. \n",
    "    * Example: articles = soup.select('div.article-link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461979f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': 'Nov 2022',\n",
      "  'excerpt': \"Or: Etiquette and table manners for pinging other people's \"\n",
      "             'servers.',\n",
      "  'title': 'Consuming APIs responsibly',\n",
      "  'url': '/2022/11/consuming-apis-responsibly'},\n",
      " {'date': 'Feb 2022',\n",
      "  'excerpt': 'Add Jekyll posts into a series with series navigation.',\n",
      "  'title': 'Create a series of posts with navigation in Jekyll',\n",
      "  'url': '/2022/02/creating-article-series-posts-navigation-jekyll'},\n",
      " {'date': 'Jan 2022',\n",
      "  'excerpt': 'Implementing light and dark mode on your Bootstrap 5 + Jekyll '\n",
      "             'website.',\n",
      "  'title': 'A practical guide to light and dark mode in Bootstrap 5 and Jekyll',\n",
      "  'url': '/2022/01/practical-light-dark-mode-jekyll-bootstrap5'},\n",
      " {'date': 'Jan 2022',\n",
      "  'excerpt': 'Celebrate 2022 with a shiny new file manager for Ubuntu!',\n",
      "  'title': 'Nemo - The Ubuntu file manager you didnâ€™t know you needed',\n",
      "  'url': '/2022/01/nemo-file-manager-ubuntu-20.04-linux-nautilus-alternative'},\n",
      " {'date': 'Jan 2022',\n",
      "  'excerpt': \"I've been working on a search engine for Fediverse instances!\",\n",
      "  'title': 'Announcing Fediverse.to!',\n",
      "  'url': '/2022/01/announcing-fediverse-to'},\n",
      " {'date': 'Nov 2021',\n",
      "  'excerpt': 'Combine Jekyll and Netlify to create pretty URL redirects as '\n",
      "             'easy as 1-2-3.',\n",
      "  'title': 'Easy pretty URL redirects with Jekyll and Netlify',\n",
      "  'url': '/2021/11/easy-pretty-url-redirects-with-jekyll-and-netlify'},\n",
      " {'date': 'Nov 2021',\n",
      "  'excerpt': 'Add a link back to the public Git hosting link for any static '\n",
      "             'Jekyll blog.',\n",
      "  'title': 'Linking Jekyll pages back to their Git source code',\n",
      "  'url': '/2021/11/linking-jekyll-pages-back-to-their-git-source-code'},\n",
      " {'date': 'Nov 2021',\n",
      "  'excerpt': 'Use CLI tools to generate resized and optimised thumbnails for '\n",
      "             'articles header images.',\n",
      "  'title': 'Optimising JPG and PNG images for a Jekyll website',\n",
      "  'url': '/2021/11/optimising-jpg-and-png-images-for-a-jekyll-blog'},\n",
      " {'date': 'Nov 2021',\n",
      "  'excerpt': 'Display search results from any JSON data object in the browser '\n",
      "             'using Lunr.js.',\n",
      "  'title': 'Quick and easy client-side JavaScript search with Lunr.js',\n",
      "  'url': '/2021/11/using-lunr-js-to-create-client-side-website-search-index'},\n",
      " {'date': 'Oct 2021',\n",
      "  'excerpt': 'Blur the line between desktop and web by letting the OS style '\n",
      "             'your website or webapp.',\n",
      "  'title': 'Creating light and dark themes for websites the right way using '\n",
      "           'prefers-color-scheme',\n",
      "  'url': '/2021/10/creating-light-and-dark-themes-for-websites-correctly-using-prefers-color-scheme'},\n",
      " {'date': 'Oct 2021',\n",
      "  'excerpt': 'Notion is an awesome life manager. And Mastodon is great for '\n",
      "             'decentralised internet shenanigans. With Nativefier, I can now '\n",
      "             'enjoy them as apps on Ubuntu 20.04.',\n",
      "  'title': 'Make Linux apps for Notion, Mastodon, or any web app using '\n",
      "           'Nativefier',\n",
      "  'url': '/2021/10/make-linux-apps-for-notion-mastodon-webapps-using-nativefier'},\n",
      " {'date': 'Oct 2021',\n",
      "  'excerpt': 'Auto-generate Jekyll configuration files with content and avoid '\n",
      "             'creating an API backend.',\n",
      "  'title': 'Inserting dynamic data into Jekyll static sites using Python or '\n",
      "           'Bash',\n",
      "  'url': '/2021/10/inserting-dynamic-data-into-jekyll-static-sites-using-python-or-bash'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': 'Ansible is the answer to custom scripts and tooling that '\n",
      "             'eventually snowball into a kludge which breaks more things than '\n",
      "             'it fixes.',\n",
      "  'title': 'Introduction to Ansible',\n",
      "  'url': '/2021/08/introduction-to-ansible'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': 'What is YAML and why is it about time we started using it?',\n",
      "  'title': 'Introduction to YAML',\n",
      "  'url': '/2021/08/introduction-to-yaml'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': 'Jekyll is a framework for building websites - write your content '\n",
      "             'in Markdown, use HTML/CSS for structure and presentation, and '\n",
      "             'Jekyll compiles it all into static HTML. No servers. No '\n",
      "             'backends. No fuss.',\n",
      "  'title': 'Introduction to Jekyll',\n",
      "  'url': '/2021/08/introduction-to-jekyll'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': 'If you ever need to test an app and a database, did you know you '\n",
      "             'can use Vagrant to bring up multiple testing machines at once? '\n",
      "             \"Here's how.\",\n",
      "  'title': 'Multi-machine Setup and Configuration with Vagrant',\n",
      "  'url': '/2021/08/multi-machine-setup-and-configuration-with-vagrant'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': 'Ansible works well to provision a Vagrant box with everything '\n",
      "             'installed from the get-go.',\n",
      "  'title': 'Provisioning with Vagrant',\n",
      "  'url': '/2021/08/provisioning-with-vagrant'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': 'Vagrant helps you run other operating systems on your computer, '\n",
      "             'meaning you can build things, test things, and do crazy shit '\n",
      "             'without blowing up your own system.',\n",
      "  'title': 'Introduction to Vagrant',\n",
      "  'url': '/2021/08/introduction-to-vagrant'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': 'Web-scraping is a useful but often neglected technical skill. '\n",
      "             'The BeautifulSoup library in Python makes extracting HTML from '\n",
      "             'web pages easy. Do with that what you will ;)',\n",
      "  'title': 'A Guide to Web Scraping in Python using BeautifulSoup',\n",
      "  'url': '/2021/08/a-guide-to-web-scraping-in-python-using-beautifulsoup'},\n",
      " {'date': 'Aug 2021',\n",
      "  'excerpt': \"I recently discovered that Jekyll's config.yml can be used to \"\n",
      "             \"define custom variables for reusing content. I feel like I've \"\n",
      "             'been living under a rock all this time. But to err over and over '\n",
      "             'again is human.',\n",
      "  'title': 'Using variables in Jekyll to define custom content',\n",
      "  'url': '/2021/08/using-variables-in-jekyll-to-define-custom-content'},\n",
      " {'date': 'Jul 2021',\n",
      "  'excerpt': \"In this article, I'll highlight some ideas for Jekyll \"\n",
      "             'collections, blog category pages, responsive web-design, and '\n",
      "             'netlify.toml to make static website maintenance a breeze.',\n",
      "  'title': 'The evolution of ayushsharma.in: Jekyll, Bootstrap, Netlify, '\n",
      "           'static websites, and responsive design.',\n",
      "  'url': '/2021/07/the-evolution-of-ayushsharma-in'},\n",
      " {'date': 'Jul 2021',\n",
      "  'excerpt': \"These are the top 5 lessons I've learned after 5 years of \"\n",
      "             'Terraform-ing.',\n",
      "  'title': '5 key best practices for sane and usable Terraform setups',\n",
      "  'url': '/2021/07/5-key-best-practices-for-sane-and-usable-terraform-setups'},\n",
      " {'date': 'Jul 2021',\n",
      "  'excerpt': 'In this article I explore Checkov, a static code analysis tool '\n",
      "             'for Terraform.',\n",
      "  'title': 'Cloud Infrastructure SAST: Scanning Terraform for security '\n",
      "           'vulnerabilities and non-compliance using Checkov',\n",
      "  'url': '/2021/07/cloud-infrastructure-sast-terraform-checkov'},\n",
      " {'date': 'Jul 2021',\n",
      "  'excerpt': \"I've just discovered that Terraform can deploy Helm Charts as \"\n",
      "             \"well. But I'm not sure if I like it.\",\n",
      "  'title': 'Terraform + Helm: A match made in heaven/hell?',\n",
      "  'url': '/2021/07/terraform-plus-helm-a-match-made-in-heaven-hell'},\n",
      " {'date': 'Jul 2021',\n",
      "  'excerpt': 'In this tutorial, I will show you how to automatically create '\n",
      "             'multiple Applications in ArgoCD using ArgoCD!',\n",
      "  'title': 'Automating ArgoCD using ArgoCD!',\n",
      "  'url': '/2021/07/automating-argocd-using-argocd'},\n",
      " {'date': 'Jul 2021',\n",
      "  'excerpt': 'In this post we meet ArgoCD: a simple pull-based GitOps '\n",
      "             'deployment tool which syncs K8s manifest files with a cluster '\n",
      "             'for easy and no-nonsense deployments.',\n",
      "  'title': 'Getting started with ArgoCD',\n",
      "  'url': '/2021/07/getting-started-with-argocd'},\n",
      " {'date': 'Sep 2020',\n",
      "  'excerpt': 'Create parameterized AWS security groups quickly and '\n",
      "             'consistently with Terraform Registry.',\n",
      "  'title': 'Creating ready-to-use AWS Security Groups using Terraform '\n",
      "           'Registry, Named Groups, and Named Rules',\n",
      "  'url': '/2020/09/creating-ready-to-use-aws-security-groups-using-terraform-registry-named-groups-and-named-rules'},\n",
      " {'date': 'Sep 2020',\n",
      "  'excerpt': 'Create parameterized AWS VPCs quickly and consistently with '\n",
      "             'Terraform Registry.',\n",
      "  'title': 'Creating AWS VPCs in 2 minutes with Terraform Registry',\n",
      "  'url': '/2020/09/creating-aws-vpcs-in-2-minutes-with-terraform-registry'},\n",
      " {'date': 'Jun 2020',\n",
      "  'excerpt': \"Build and push Docker images to DockerHub using GitLab's \"\n",
      "             'Pipelines feature.',\n",
      "  'title': 'Continuous delivery on GitLab: Pushing Docker images to DockerHub '\n",
      "           'using GitLab Pipelines',\n",
      "  'url': '/2020/06/continuous-delivery-on-gitlab-pushing-docker-images-to-dockerhub-using-gitlab-pipelines'},\n",
      " {'date': 'Jun 2020',\n",
      "  'excerpt': 'A tutorial on how to configure automatic snapshots of '\n",
      "             'Elasticsearch using the in-built Snapshot Lifecycle Manager on '\n",
      "             'Google Compute Engine.',\n",
      "  'title': 'Configuring Elasticsearch snapshots using SLM on Google Compute '\n",
      "           'Engine',\n",
      "  'url': '/2020/06/configuring-elasticsearch-snapshots-using-slm-on-google-compute-engine'},\n",
      " {'date': 'Jun 2020',\n",
      "  'excerpt': 'Your time and attention is your primary resource, so deploy it '\n",
      "             'wisely.',\n",
      "  'title': '\\u200b\\u200bWorking From Home and Software Engineering',\n",
      "  'url': '/2020/06/working-from-home-and-software-engineering'},\n",
      " {'date': 'Apr 2020',\n",
      "  'excerpt': '2020 is the year startups are trying to save aggresively on '\n",
      "             'cloud spend. I list down some key learnings based on my '\n",
      "             'experience.',\n",
      "  'title': '\\u200b\\u200bThe Virus \\u200bðŸ˜·\\u200b and the Cloud \\u200bâ›…\\u200b: '\n",
      "           'Tips on AWS cost-saving in these weird \\u200bðŸ¤¯\\u200b times',\n",
      "  'url': '/2020/04/the-virus-and-the-cloud-tips-on-aws-cost-saving'},\n",
      " {'date': 'Mar 2020',\n",
      "  'excerpt': 'I love Bitbucket Pipelines, and debugging them on your laptop is '\n",
      "             \"even easier thanks to Docker containers. I'll show you how to \"\n",
      "             'debug Serverless deployments and diagnose broken builds.',\n",
      "  'title': 'Replicating Bitbucket Pipelines on your laptop for local debugging',\n",
      "  'url': '/2020/03/replicating-bitbucket-pipelines-on-your-laptop-for-local-debugging'},\n",
      " {'date': 'Feb 2020',\n",
      "  'excerpt': \"I'll show you how to allow one Bitbucket repo to clone another \"\n",
      "             'during a Pipeline build.',\n",
      "  'title': 'Cloning another Bitbucket repository in Bitbucket Pipelines',\n",
      "  'url': '/2020/02/cloning-another-bitbucket-repo-in-bitbucket-pipelines'},\n",
      " {'date': 'Feb 2020',\n",
      "  'excerpt': 'Git submodules makes it easy have repos for common dependencies, '\n",
      "             'but how to actually clone them in your Bitbucket Pipeline?',\n",
      "  'title': 'Deploying git submodules in Bitbucket Pipelines',\n",
      "  'url': '/2020/02/deploying-git-submodules-in-bitbucket-pipelines'},\n",
      " {'date': 'Aug 2019',\n",
      "  'excerpt': \"I'll show you how to build a Docker image in a Pipeline and push \"\n",
      "             'it to a container registry, in this case Amazon ECR.',\n",
      "  'title': 'Automating Amazon Elastic Container (ECR) container builds using '\n",
      "           'Bitbucket Pipelines',\n",
      "  'url': '/2019/08/automating-ecr-container-builds-using-bitbucket-pipelines'},\n",
      " {'date': 'Aug 2019',\n",
      "  'excerpt': 'AWS Cost & Usage Reports with AWS Athena are vital for '\n",
      "             \"understanding cloud spend. I'll show you some handy Athena \"\n",
      "             'queries to break things down.',\n",
      "  'title': 'Taming AWS costs with Cost and Usage Reports + AWS Athena',\n",
      "  'url': '/2019/08/taming-aws-costs-with-cost-and-usage-reports-and-aws-athena'},\n",
      " {'date': 'Jun 2019',\n",
      "  'excerpt': \"Bitbucket doesn't offer a dashboard yet, or an easy way to fetch \"\n",
      "             'information for all your repos and Pipelines. So I wrote a handy '\n",
      "             \"Python script for the job. It's great for configuring alerts or \"\n",
      "             'building near-real-time dashboards!',\n",
      "  'title': 'Exporting Bitucket repositories and Pipelines with Python',\n",
      "  'url': '/2019/06/exporting-bitucket-repos-pipelines-python'},\n",
      " {'date': 'Jun 2019',\n",
      "  'excerpt': 'My very first programming language was Logo! I can still '\n",
      "             'remember guiding that fuzzy little on-screen turtle to draw '\n",
      "             'simple and complex shapes. So I found the Logo Python module and '\n",
      "             'took a walk down memory lane.',\n",
      "  'title': 'Rediscovering Logo with Bob the turtle',\n",
      "  'url': '/2019/06/rediscovering-logo-with-bob-the-turtle'},\n",
      " {'date': 'May 2019',\n",
      "  'excerpt': 'The open-source Serverless framework makes it easy to build and '\n",
      "             \"deploy Lambda stacks. I'll walk you through deploying Serverless \"\n",
      "             'apps automatically using Pipelines.',\n",
      "  'title': 'Automating Serverless framework deployments using Bitbucket '\n",
      "           'Pipelines',\n",
      "  'url': '/2019/05/automating-serverless-framework-deployments-using-bitbucket-pipelines'},\n",
      " {'date': 'May 2019',\n",
      "  'excerpt': 'Pipes is another great Continuous Delivery feature in Bitbucket: '\n",
      "             'pre-built, ready-to-use, and parameterized deployment jobs.',\n",
      "  'title': 'Automating AWS Lambda deployments using Bitbucket Pipelines and '\n",
      "           'Bitbucket Pipes',\n",
      "  'url': '/2019/05/automating-aws-lambda-deployments-using-bitbucket-pipelines-bitbucket-pipes'},\n",
      " {'date': 'Mar 2019',\n",
      "  'excerpt': 'Notes on implementing the basic Exchange sort algorithms in '\n",
      "             'Python.',\n",
      "  'title': 'Algorithms in Python: Exchange Sorts',\n",
      "  'url': '/2019/03/algorithms-in-python-exchange-sorts'},\n",
      " {'date': 'Jan 2019',\n",
      "  'excerpt': 'The Phoenix Project is one of the most approachable books for '\n",
      "             'DevOps available today. Highly recommended, especially if you '\n",
      "             \"don't already know Conway's Law.\",\n",
      "  'title': 'The Three Ways of DevOps: Notes on The Phoenix Project',\n",
      "  'url': '/2019/01/the-three-ways-of-devops-notes-on-the-phoenix-project'},\n",
      " {'date': 'Oct 2018',\n",
      "  'excerpt': 'My Udacity Python Nanodegree introduced using NumPy to handle '\n",
      "             'large arrays and datasets in Python. I put some notes togther '\n",
      "             'for referencing later.',\n",
      "  'title': 'Working with NumPy in Python',\n",
      "  'url': '/2018/10/working-with-numpy-in-python'},\n",
      " {'date': 'Sep 2018',\n",
      "  'excerpt': 'Some quick notes describing the basic data types in Python3 and '\n",
      "             'their features.',\n",
      "  'title': 'Data Types in Python',\n",
      "  'url': '/2018/09/data-types-in-python'},\n",
      " {'date': 'Sep 2018',\n",
      "  'excerpt': 'Tweet-Toot is my personal project, a Twitter relay for the '\n",
      "             'Mastodon social network. I recently dockerized the setup and put '\n",
      "             'these notes together to explain the process.',\n",
      "  'title': 'Dockerizing Tweet-Toot: A practical guide to deploying your app '\n",
      "           'using Docker',\n",
      "  'url': '/2018/09/dockerizing-tweet-toot-a-practical-guide-to-deploying-your-app-using-docker'},\n",
      " {'date': 'Sep 2018',\n",
      "  'excerpt': 'SublimeText has some cool plugins for setting up a basic Jekyll '\n",
      "             'development environment. Take a look.',\n",
      "  'title': 'SublimeText 3 setup for Jekyll development',\n",
      "  'url': '/2018/09/sublime-text-3-setup-for-jekyll-development'},\n",
      " {'date': 'Sep 2018',\n",
      "  'excerpt': \"Gartner's Magic Quadrants was one of the the first industry \"\n",
      "             \"reports I read which covered where the cloud vendor's were \"\n",
      "             'headed and what their strengths and weaknesses were. I took some '\n",
      "             'time to consolidate the Gartner findings over the last 5 years '\n",
      "             'for comparison.',\n",
      "  'title': \"Gartner's Magic Quadrants: A summary of cloud \"\n",
      "           'Infrastructure-as-a-Service providers over the last 5 years',\n",
      "  'url': '/2018/09/gartners-magic-quadrants-a-summary-of-cloud-infrastructure-as-a-service-providers-over-the-last-5-years'},\n",
      " {'date': 'Sep 2018',\n",
      "  'excerpt': 'I joined the Mastodon social network in 2016 and felt a need for '\n",
      "             'building a Twitter relay. We all left the birdsite for many '\n",
      "             'reasons but not the people we met. So this project is a way to '\n",
      "             'bring some of them over to Mastodon, in practice if not in '\n",
      "             'spirit.',\n",
      "  'title': 'Tweet-Toot: Building a bot for Mastodon using Python',\n",
      "  'url': '/2018/09/tweet-toot-building-a-bot-for-mastodon-using-python'},\n",
      " {'date': 'Jul 2018',\n",
      "  'excerpt': 'I love Cloudflare, but after facing some issues with TTFB I '\n",
      "             'decided to move to StackPath, which proved to be a lot faster '\n",
      "             'and feature-rich.',\n",
      "  'title': 'Moving from CloudFlare to StackPath',\n",
      "  'url': '/2018/07/moving-from-cloudflare-to-stackpath'},\n",
      " {'date': 'Jul 2018',\n",
      "  'excerpt': \"I went through one of Gartner's reports, and it says the key to \"\n",
      "             'breaking vendor lock-in is to commit fully to a single '\n",
      "             'technology vendor, be it a cloud software provider, a social '\n",
      "             'network, or our favorite sharing app. It seems controversial on '\n",
      "             'the surface, but I wanted to jot down some quick notes. Maybe '\n",
      "             'the approach is worth experimenting with?',\n",
      "  'title': 'Understanding vendor lock-in and breaking the cycle',\n",
      "  'url': '/2018/07/understanding-vendor-lock-in-and-breaking-the-cycle'},\n",
      " {'date': 'Jul 2018',\n",
      "  'excerpt': 'Terraform enables more than infrastructure provisioning, you can '\n",
      "             'even use it for deployments. Combine it with Packer, and you can '\n",
      "             'have a very powerful immutable rolling deployment pipeline.',\n",
      "  'title': 'Rolling clusters for deployment with Terraform',\n",
      "  'url': '/2018/07/rolling-clusters-for-deployment-with-terraform'},\n",
      " {'date': 'Jul 2018',\n",
      "  'excerpt': \"Terraform's Modules feature allows quickly building re-usable \"\n",
      "             'infrastructure templates to provision cloud environments '\n",
      "             'repeatably. These notes will help set up a basic application for '\n",
      "             'high-availability.',\n",
      "  'title': 'Working with Terraform Modules',\n",
      "  'url': '/2018/07/working-with-terraform-modules'},\n",
      " {'date': 'Oct 2017',\n",
      "  'excerpt': 'A basic walkthrough of Terraform, the open-source, '\n",
      "             'cloud-agnostic IaC tool by HashiCorp, the makers of Vagrant.',\n",
      "  'title': 'Getting started with Terraform',\n",
      "  'url': '/2017/10/getting-started-with-terraform'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': \"It's about time we all move our web properties to HTTP/2. I list \"\n",
      "             'down some gotchas for those looking to migrate.',\n",
      "  'title': 'Upgrading to HTTP/2',\n",
      "  'url': '/2017/09/upgrading-to-http2'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'The web is a collection of inter-connected pages. This means '\n",
      "             'chances are good that someone landing on your website is coming '\n",
      "             'from another one, and when they leave your website, they take a '\n",
      "             'lot of identifiable information with them. HTTP/2 allows you to '\n",
      "             'control what happens to the referrer information when users '\n",
      "             'leave your website.',\n",
      "  'title': 'HTTP security headers: Referrer-Policy',\n",
      "  'url': '/2017/09/http-security-headers-referrer-policy'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'HTTP/2 introduced a new feature which basically just turns off '\n",
      "             \"an old default feature: the browser's hankering for figuring out \"\n",
      "             'the content type of a resource. Why and how should we turn it '\n",
      "             'off?',\n",
      "  'title': 'HTTP security headers: X-Content-Type-Options',\n",
      "  'url': '/2017/09/http-security-headers-x-content-type-options'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'Inline-frames enable very basic phishing attacks. You can just '\n",
      "             \"include a bank's main website within your own website and lure \"\n",
      "             'the user to handover their passwords. HTTP2/ comes with built-in '\n",
      "             'protection against this kind of threat.',\n",
      "  'title': 'HTTP security headers: X-Frame-Options',\n",
      "  'url': '/2017/09/http-security-headers-x-frame-options'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'HSTS is a security feature which prevents users from accessing '\n",
      "             'your website over non-secure HTTP. It comes with HTTP/2, is easy '\n",
      "             \"to turn on, but very hard to turn off. Here's the why and how.\",\n",
      "  'title': 'HTTP security headers: HTTP-Strict-Transport-Security',\n",
      "  'url': '/2017/09/http-security-headers-http-strict-transport-security'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': \"HTTP/2 comes with built-in protection for XSS. Here's what it \"\n",
      "             'does and how to turn it on.',\n",
      "  'title': 'HTTP security headers: X-XSS-Protection',\n",
      "  'url': '/2017/09/http-security-headers-x-xss-protection'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': \"HTTP/2's CSP let's you define a white-list of what's allowed and \"\n",
      "             \"what's blocked on your website. This lets browsers block \"\n",
      "             \"third-party trackers which try to annoy/harm your users. Here's \"\n",
      "             'the why and how.',\n",
      "  'title': 'HTTP security headers: Content-Security-Policy',\n",
      "  'url': '/2017/09/http-security-headers-content-security-policy'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'I added the Disqus commenting platform to my blog some time ago. '\n",
      "             'And then I found out that it was loading WAY TOO MANY tracking '\n",
      "             'cookies inline and profiling my website users. This is how you '\n",
      "             'build Orwellian software. And shitty software.',\n",
      "  'title': \"I'm killing Disqus comments on my blog. Here's why.\",\n",
      "  'url': '/2017/09/im-killing-disqus-comments-on-my-blog-heres-why'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'Slack has become a favorite of DevOps/SRE teams across the '\n",
      "             \"globe. It's a very easy-to-use and programmatic messaging \"\n",
      "             \"platform. Here's the quick and easy process to posting messages \"\n",
      "             'to your Slack group from Python.',\n",
      "  'title': 'Posting messages to Slack using incoming webhooks and Python3 '\n",
      "           'Requests API',\n",
      "  'url': '/2017/09/posting-messages-to-slack-using-incoming-webhooks-and-python-requests-api'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'Packer is an amazing golden image builder. Ansible is a great '\n",
      "             \"deployment tool. So let's use them together!\",\n",
      "  'title': 'Using Packer and Ansible to create immutable servers, deploying '\n",
      "           'code, and recycling instances',\n",
      "  'url': '/2017/09/using-packer-and-ansible-to-create-immutable-servers-deploying-code-and-recycling-instances'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'Packer. Basically Docker for whole VMs. Another great tool by '\n",
      "             'HashiCorp, this one modernises an old formula but retains the '\n",
      "             'simplicity. Building immutable servers was never this easy.',\n",
      "  'title': 'Getting started with Packer',\n",
      "  'url': '/2017/09/getting-started-with-packer'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'I took a walk down memory lane to try and figure out how much my '\n",
      "             'daily work has changed. The concepts are still the same, but the '\n",
      "             'tools have become bigger, because our needs have shifted '\n",
      "             'dramatically over the years.',\n",
      "  'title': \"The different ways I've deployed code over the years: the road to \"\n",
      "           'Immutable Servers',\n",
      "  'url': '/2017/09/the-different-ways-ive-deployed-code-over-the-years-the-road-to-immutable-servers'},\n",
      " {'date': 'Sep 2017',\n",
      "  'excerpt': 'A quick script for ad-hoc health-checking of load balancer '\n",
      "             'instances.',\n",
      "  'title': 'Testing AWS Elastic Load Balancer health check endpoints with '\n",
      "           'Python',\n",
      "  'url': '/2017/09/testing-aws-elastic-load-balancer-health-check-endpoints-with-python'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'I recently discovered InfluxDB as a great write-heavy database '\n",
      "             'for storing metrics. These are my notes on monitoring the golden '\n",
      "             'signals in Nginx using Collectd and InfluxDB.',\n",
      "  'title': 'Complete Nginx Monitoring with Collectd and InfluxDB',\n",
      "  'url': '/2017/08/complete-nginx-monitoring-with-collectd-and-influxdb'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': \"Because why not? Here's how to build your Jekyll website and \"\n",
      "             'deploy it to a VM of your choice.',\n",
      "  'title': 'Deploying Jekyll blog automatically using Bitbucket Pipelines',\n",
      "  'url': '/2017/08/deploying-jekyll-blog-automatically-using-bitbucket-pipelines'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'If you ever need to migrate a MySQL database to InfluxDB, say if '\n",
      "             'you were using MySQL as a metrics database because you were too '\n",
      "             'busy not knowing Influx even existed, then this handy Python '\n",
      "             'script can do the job and take care of schema migrations too.',\n",
      "  'title': 'Migrating MySQL database tables to InfluxDB',\n",
      "  'url': '/2017/08/migrating-mysql-database-tables-to-influxdb'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'A handy bash script to backup your InfluxDB database to AWS S3; '\n",
      "             'great for cron jobs.',\n",
      "  'title': 'Backing up InfluxDB databases to S3',\n",
      "  'url': '/2017/08/backing-up-influxdb-databases-to-s3'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'Grafana provides out-of-the-box support for InfluxDB, so '\n",
      "             \"visualising the metrics you're collecting using Collectd, etc., \"\n",
      "             \"is straightforward. Here's how to do it.\",\n",
      "  'title': 'Setting Up Grafana to use Collectd and InfluxDB',\n",
      "  'url': '/2017/08/setting-up-grafana-to-use-collectd-and-influxdb'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'A quick copy-paste-able process for installing Collectd and '\n",
      "             'InfluxDB on your Mac for some local testing.',\n",
      "  'title': 'Setting up Collectd and InfluxDB on Mac OS X',\n",
      "  'url': '/2017/08/setting-up-collectd-and-influxdb-on-mac-os-x'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'A quick comparison of relational vs time-series databases, '\n",
      "             'followed by a brief hands-on tutorial for InfluxDB on a local '\n",
      "             'Mac OS.',\n",
      "  'title': 'Getting Started with time-series data using InfluxDB',\n",
      "  'url': '/2017/08/getting-started-with-time-series-data-using-influxdb'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'Collectd, a C-based daemon, is a fast and lightweight metrics '\n",
      "             'shipper.',\n",
      "  'title': 'Getting started with server metrics collection with Collectd',\n",
      "  'url': '/2017/08/getting-started-with-server-metrics-collecting-with-collectd'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'A very basic reality of computer networking is that... it fails. '\n",
      "             'And when it does, there are ways to retry your connections to '\n",
      "             'make life easier for you and other clients as well.',\n",
      "  'title': 'Retry Strategies for Transient Failures',\n",
      "  'url': '/2017/08/retry-strategies-for-transient-failures'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'AWS Elastic load balancers do their job well, but they can get '\n",
      "             'pricey. So naturally I tried using Route53 for load balancing '\n",
      "             'traffic. It was a lot harder than I thought, and while this '\n",
      "             \"experiment didn't succeed, I'm noting my approach here for \"\n",
      "             'better luck next time.',\n",
      "  'title': 'Using Route 53 as a Load Balancer',\n",
      "  'url': '/2017/08/using-route-53-as-a-load-balancer'},\n",
      " {'date': 'Aug 2017',\n",
      "  'excerpt': 'A handy bash script to backup all MySQL databases to AWS S3.',\n",
      "  'title': 'MySQL Database backups to S3',\n",
      "  'url': '/2017/08/mysql-database-backups-to-s3'},\n",
      " {'date': 'Apr 2017',\n",
      "  'excerpt': 'The title really says it all: exporting data from JSON and '\n",
      "             'ingesting into Sqlite3.',\n",
      "  'title': 'Mastodon Users and Instances in Sqlite3 Using Python',\n",
      "  'url': '/2017/04/mastodon-users-and-instances-in-sqlite3-using-python'},\n",
      " {'date': 'Apr 2017',\n",
      "  'excerpt': \"I installed mutt to send email from the command-line. It's fast \"\n",
      "             'and the CLI switches are memorable. Worth a look if you use the '\n",
      "             'CLI for sending emails a lot.',\n",
      "  'title': 'The Ultimate Guide to Using Mail in Linux',\n",
      "  'url': '/2017/04/the-ultimate-guide-to-using-mail-in-linux'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'You get 3 guesses for what the solution could be...',\n",
      "  'title': \"Fixing ValueError('unknown locale: %s' % localename) in Python\",\n",
      "  'url': '/2017/03/fixing-valueError-unknown-locale-s-localename-in-python'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'Xinetd is a light-weight and straightfoward HTTP server. Not as '\n",
      "             \"powerful as Nginx, but it's great for simple things like \"\n",
      "             'configuring health checks.',\n",
      "  'title': 'Getting Started with Xinetd',\n",
      "  'url': '/2017/03/getting-started-with-xinetd'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'The Maxmind GeoIP database is useful for looking up the country '\n",
      "             'and ISP information for an IP address.',\n",
      "  'title': 'Getting City, Country and ISP of an IP address using Maxmind GeoIP',\n",
      "  'url': '/2017/03/getting-city-country-and-isp-of-an-ip-address-using-maxmind-geoip'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'I pulled the data for technology incidents for the major cloud '\n",
      "             'services. The findings were pretty interesting.',\n",
      "  'title': 'AWS, GCS, Azure and Digital Ocean incidents by service in 2016',\n",
      "  'url': '/2017/03/aws-gcs-and-azure-incidents-by-service-in-2016'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'These have been the confessions of a firefighter who ignored the '\n",
      "             'smoke.',\n",
      "  'title': 'I Have Something to Say II',\n",
      "  'url': '/2017/03/i-have-something-to-say-ii'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'At work, one of my recent projects involved setting up a '\n",
      "             'multi-region failover with weighted-routing support. Thankfully, '\n",
      "             \"Route53 has all of these built-in. Here's how to do it.\",\n",
      "  'title': 'Using Weighted, Geo and Fail-over Routeing in Route 53',\n",
      "  'url': '/2017/03/using-weighted-geo-failover-routeing-in-route-53'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': \"It's 2017 and the cloud has matured by leaps and bounds. So do \"\n",
      "             'we still need staging servers?',\n",
      "  'title': 'You still might need a staging server in 2017',\n",
      "  'url': '/2017/03/you-might-still-need-a-staging-server-in-2017'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'I pulled the data for technology incidents on the major cloud '\n",
      "             'platforms. The findings were pretty interesting.',\n",
      "  'title': 'AWS, GCS, Azure and Digital Ocean incidents in 2016',\n",
      "  'url': '/2017/03/aws-gcs-and-azure-incidents-in-2016'},\n",
      " {'date': 'Mar 2017',\n",
      "  'excerpt': 'Ten years from now, if or when I am in another job, no one is '\n",
      "             'going to care whether I ran my production servers with my heart '\n",
      "             'and soul. They will care if I saved money, they will care if I '\n",
      "             'ran it efficiently, but you can do those things while still '\n",
      "             'compromising your values.',\n",
      "  'title': 'I Have Something to Say',\n",
      "  'url': '/2017/03/i-have-something-to-say'},\n",
      " {'date': 'Feb 2017',\n",
      "  'excerpt': 'A step-by-step guide for connecting 2 AWS VPSs using self-hosted '\n",
      "             'StrongSwan VPNs.',\n",
      "  'title': 'Connecting VPCs in 2 AWS Regions (Site-to-site VPN)',\n",
      "  'url': '/2017/02/connecting-vpcs-in-2-aws-regions-site-to-site-vpn'},\n",
      " {'date': 'Feb 2017',\n",
      "  'excerpt': 'These are instructions for installing PHP7, MySQL 5.7 and Nginx '\n",
      "             '1.10 on Ubuntu 16.04. Very copy-paste-able.',\n",
      "  'title': 'Installing PHP 7 FPM + MySQL 5.7 + Nginx 1.10 on Ubuntu 16.04',\n",
      "  'url': '/2017/02/installing-php7-fpm-mysql-5.7-nginx-1.10-on-ubuntu-16.04'},\n",
      " {'date': 'Feb 2017',\n",
      "  'excerpt': 'Some notes on Logical Volume Manager. What it is, why it is, and '\n",
      "             'how to use it.',\n",
      "  'title': 'Working with Logical Volume Manager (LVM)',\n",
      "  'url': '/2017/02/working-with-logical-volume-manager-lvm'},\n",
      " {'date': 'Jan 2017',\n",
      "  'excerpt': \"Logrotate is one of those built-in Linux things that we don't \"\n",
      "             'use often enough. Rotating logs, archiving them to S3, pushing '\n",
      "             \"them to some remote server/endpoint, etc. It's all doable with \"\n",
      "             'Logrotate.',\n",
      "  'title': 'Fiddling with Logrotate',\n",
      "  'url': '/2017/01/fiddling-with-logrotate'},\n",
      " {'date': 'Jan 2017',\n",
      "  'excerpt': 'Route53: what, why, how, why not.',\n",
      "  'title': 'AWS Route 53 Notes',\n",
      "  'url': '/2017/01/notes-on-aws-route53'},\n",
      " {'date': 'Jan 2017',\n",
      "  'excerpt': 'I ran hdparm and dd on GP2, PIOPS, SC1, ST1, and Magnetic EBS '\n",
      "             'volumes. Check out the results.',\n",
      "  'title': 'AWS EBS Types Read/Write Benchmarks',\n",
      "  'url': '/2017/01/aws-ebs-types-read-write-benchmarks'},\n",
      " {'date': 'Oct 2016',\n",
      "  'excerpt': 'AWS spot instances provide 90% savings over on-demand servers. '\n",
      "             'The downside? AWS can yank them whenever they want and you have '\n",
      "             '2 minutes to back things up. How do you know when the starting '\n",
      "             'pistol fires?',\n",
      "  'title': 'Logging AWS spot instance termination',\n",
      "  'url': '/2016/10/logging-aws-spot-instance-termination'},\n",
      " {'date': 'Oct 2016',\n",
      "  'excerpt': \"If you're using a Lua module with Nginx, then decompressing \"\n",
      "             'GZIPped data requires some extra handling.',\n",
      "  'title': 'Decompressing request using GZIP with Nginx',\n",
      "  'url': '/2016/10/decompressing-request-using-gzip-with-nginx'},\n",
      " {'date': 'Oct 2016',\n",
      "  'excerpt': \"It's pretty hard to compress output with GZIP in PHP 5.3, but in \"\n",
      "             \"case you ever need to, here's how.\",\n",
      "  'title': 'Compressing output using GZIP with PHP 5.3',\n",
      "  'url': '/2016/10/compressing-output-using-gzip-with-php-5.3'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': \"I'll explore the basics of self-hosted load-balancing with Nginx \"\n",
      "             'using a convenient testing setup using Vagrant.',\n",
      "  'title': 'Introduction to Load-balancing with Nginx',\n",
      "  'url': '/2016/08/introduction-to-load-balancing-with-nginx'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': \"Here's how to read a response JSON web token in PHP Phalcon.\",\n",
      "  'title': 'Reading JWT token in Phalcon',\n",
      "  'url': '/2016/08/reading-jwt-token-in-phalcon'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'After CodeIgniter, Phalcon was the second PHP framework that I '\n",
      "             'used. Blazingly fast and easy-to-use, one of the first things I '\n",
      "             'did was create a custom 404 response controller.',\n",
      "  'title': 'Setting Custom 404 Controller in Phalcon',\n",
      "  'url': '/2016/08/setting-custom-404-controller-in-phalcon'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'A quick guide to the different DNS record types.',\n",
      "  'title': 'DNS Record Types',\n",
      "  'url': '/2016/08/dns-record-types'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': \"Let's Encrypt is the self-hosted, industry-standard method of \"\n",
      "             \"generating SSL certificates for your applications. If you're \"\n",
      "             \"still paying for SSL certificates you're doing it wrong.\",\n",
      "  'title': \"Securing Nginx with Let's Encrypt Free SSL Certificate\",\n",
      "  'url': '/2016/08/securing-nginx-with-lets-encrypt-free-ssl-certificate'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'The differences between vertical and horizontal scaling may be '\n",
      "             \"simple, but they're critical to using cloud technologies \"\n",
      "             'effectively.',\n",
      "  'title': 'Vertical Scaling vs Horizontal Scaling',\n",
      "  'url': '/2016/08/vertical-scaling-vs-horizontal-scaling'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'A quick guide of essential VIM shortcuts.',\n",
      "  'title': 'Essential VIM Keyboard Shortcuts',\n",
      "  'url': '/2016/08/essential-vim-keyboard-shortcuts'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'AWS SQS: what, why, how, why not.',\n",
      "  'title': 'Notes on AWS SQS',\n",
      "  'url': '/2016/08/notes-on-aws-sqs'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'Innobackupex, part of Percona Xtrabackup, can perform physical '\n",
      "             'backups of your MySQL databases.',\n",
      "  'title': 'MySQL Physical Backup with Innobackupex',\n",
      "  'url': '/2016/08/mysql-physical-backup-with-innobackupex'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'MySQL partitioning basics: what, why, and how.',\n",
      "  'title': 'Introduction to MySQL Partitioning',\n",
      "  'url': '/2016/08/introduction-to-mysql-partitioning'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'The legacy logging infrastructure we have to deal with today was '\n",
      "             'designed for humans and not machines, so a lot of effort is '\n",
      "             'wasted trying to make backend systems understand log data.',\n",
      "  'title': 'Introduction to Fluentd',\n",
      "  'url': '/2016/08/introduction-to-fluentd'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'A quick reference of NANO shortcuts.',\n",
      "  'title': 'NANO Keyboard Shortcuts',\n",
      "  'url': '/2016/08/nano-keyboard-shortcuts'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'The following document assesses the possibility of using JWT '\n",
      "             '(pronounced \"jot\") as a token exchange mechanism for APIs.',\n",
      "  'title': 'JSON Web Tokens',\n",
      "  'url': '/2016/08/json-web-tokens'},\n",
      " {'date': 'Aug 2016',\n",
      "  'excerpt': 'Hello, World, you little blue thing...',\n",
      "  'title': 'Hello @World',\n",
      "  'url': '/2016/08/hello-world'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "url = 'https://www.ayush.nz/technology'  # URL of the page to scrape\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# HTML element\n",
    "\"\"\"\n",
    "<div class=\"article-link\">\n",
    "    <p>\n",
    "        <a href=\"/2022/11/consuming-apis-responsibly\" title=\"Consuming APIs responsibly\">Consuming APIs responsibly</a><span class=\"muted\"> / Nov 2022</span>\n",
    "    </p>\n",
    "    <div class=\"excerpt\">\n",
    "        Or: Etiquette and table manners for pinging other people's servers.\n",
    "        <img src=\"https://www.ayush.nz/static/images/img-normal/2022-11-21-consuming-apis-responsibly.png\" alt=\"Banner image for Consuming APIs responsibly\">\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# Content parsing\n",
    "html = BeautifulSoup(response.text, 'html.parser')\n",
    "articles = html.select('div.article-link')  # Select article containers\n",
    "\n",
    "my_data = []\n",
    "\n",
    "# Important function!\n",
    "for article in articles:\n",
    "    try:\n",
    "        # Extract title from <a> tag\n",
    "        title_tag = article.find('a')\n",
    "        title = title_tag.get_text(strip=True)\n",
    "        url = title_tag['href']\n",
    "\n",
    "        # Extract date from the muted span\n",
    "        date = article.find('span', class_='muted').get_text(strip=True).replace('/', '').strip()\n",
    "     \n",
    "        # Extract excerpt (some articles have images in excerpts)\n",
    "        excerpt_div = article.find('div', class_='excerpt')\n",
    "        if excerpt_div:\n",
    "            # Remove any images from excerpt\n",
    "            for img in excerpt_div.find_all('img'):\n",
    "                img.decompose()\n",
    "            excerpt = excerpt_div.get_text(strip=True)\n",
    "        else:\n",
    "            excerpt = \"No excerpt available\"\n",
    "\n",
    "        # Append the data to the list\n",
    "        my_data.append({\"title\": title, \"url\":url, \"date\":date, \"excerpt\":excerpt})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article: {e}\")\n",
    "        continue\n",
    "\n",
    "pprint(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf07ed",
   "metadata": {},
   "source": [
    "### Exercise 2 - API Usage\n",
    "Use the public API endpoint to request data: https://jsonplaceholder.typicode.com/posts, using requests and NumPy libraries for Python, and httr and jsonlite in R, to save an array with all userId.\n",
    "\n",
    "* requests.get(api_url) â€“ Sends a GET request to an API. \n",
    "    * Example: response = requests.get(\"https://jsonplaceholder.typicode.com/posts\") \n",
    "* response.json() â€“ Parses the API response as JSON. \n",
    "    * Example: data = response.json() \n",
    "* np.array(data) â€“ Converts a list into a NumPy array. \n",
    "    * Example: array_data = np.array([1, 2, 3]) \n",
    "* np.savetxt(file_path, array, delimiter=',', fmt='%d') â€“ Saves an array to a CSV file. \n",
    "    * Example: np.savetxt(\"output.csv\", array_data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9c96a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array de ids: [ 1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  3  3  3  3\n",
      "  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5\n",
      "  5  5  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  8  8\n",
      "  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10\n",
      " 10 10 10 10]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Define the API endpoint\n",
    "api_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "\n",
    "# Example of the data:\n",
    "#  {\n",
    "#    \"userId\": 1,\n",
    "#    \"id\": 1,\n",
    "#    \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
    "#    \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
    "#  },\n",
    "#  {\n",
    "#    \"userId\": 1,\n",
    "#    \"id\": 2,\n",
    "#    \"title\": \"qui est esse\",\n",
    "#    \"body\": \"est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi nulla\"\n",
    "#  },\n",
    "#  {\n",
    "#    \"userId\": 1,\n",
    "#    \"id\": 3,\n",
    "#    \"title\": \"ea molestias quasi exercitationem repellat qui ipsa sit aut\",\n",
    "#    \"body\": \"et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut\"\n",
    "#  }, ...\n",
    "\n",
    "try:\n",
    "    # Send a GET request to the API\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract the userIds\n",
    "        user_ids = [post['userId'] for post in data]\n",
    "\n",
    "        # Convert the list to a NumPy array\n",
    "        users_ids_array = np.array(user_ids)\n",
    "\n",
    "        # Specify the file path where you want to save the CSV file\n",
    "        file_path = 'api_saved_ids.csv'\n",
    "\n",
    "        # Save the NumPy array as a CSV file\n",
    "        api_saved_ids_csv = np.savetxt(file_path, users_ids_array, delimiter=',', fmt='%d')\n",
    "\n",
    "        # Print the array\n",
    "        print(\"Array de ids:\", users_ids_array)\n",
    "\n",
    "        # Calculate the mean of user IDs\n",
    "        np.mean(users_ids_array)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Unable to fetch data from the API. Status code:\", response.status_code)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1c6e2",
   "metadata": {},
   "source": [
    "### Exercise 3 - Data Load\n",
    "Given the dataset diabetes.csv, load the data using pandas (Python) and the read function in R, sort by column â€˜BloodPressureâ€™, and then save the resulting file in CSV.\n",
    "\n",
    "* pd.read_csv(file_path) â€“ Reads a CSV file into a Pandas DataFrame. \n",
    "    * Example: df = pd.read_csv(\"data.csv\") \n",
    "* df.sort_values(by='column_name') â€“ Sorts DataFrame by a column. \n",
    "    * Example: sorted_df = df.sort_values(by='Age') \n",
    "* df.to_csv('output.csv', index=False) â€“ Saves DataFrame to a CSV file. \n",
    "    * Example: df.to_csv(\"sorted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9169aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_manipulate_data(file_path):\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        # Load the dataframe\n",
    "        df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "        # Manipulate the data to sort by column: BloodPressure\n",
    "        sorted_df = df.sort_values(by='BloodPressure')\n",
    "\n",
    "        # Save the manipulated data to a new CSV file\n",
    "        save_df = df.to_csv(\"sorted.csv\", index=False)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function to load and manipulate the data after the user specify the path to the file\n",
    "load_and_manipulate_data(input(\"Enter the path to the CSV file: \")) # Since the file is in the same folder as the script just type: diabetes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863b83b",
   "metadata": {},
   "source": [
    "### Exercise 4 - SQL Database Interaction\n",
    "Create the following databases, insert the following data, and print the tables using the SQL libraries SQLite (Python) and RSQLite (R).\n",
    "\n",
    "* sqlite3.connect(db_file) â€“ Establishes a SQLite database connection. \n",
    "    * Example: conn = sqlite3.connect(\"database.db\") \n",
    "* cursor.execute(\"CREATE TABLE ...\") â€“ Executes SQL commands. \n",
    "    * Example: cursor.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT)\") \n",
    "* cursor.execute(\"INSERT INTO table VALUES (...)\") â€“ Inserts data. \n",
    "    * Example: cursor.execute(\"INSERT INTO users (name) VALUES ('Alice')\") \n",
    "* cursor.fetchall() â€“ Fetches all rows from a query result. \n",
    "    * Example: data = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Students Table:\n",
      "[(1, 'John Doe', 20)]\n",
      "\n",
      "Grades Table:\n",
      "[(1, 'Math', 90, 1)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Function to create tables\n",
    "def create_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create the \"students\" table\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE students (\n",
    "            student_id INTEGER PRIMARY KEY,\n",
    "            name TEXT NOT NULL,\n",
    "            age INTEGER\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Create the \"grades\" table with a foreign key reference to students\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE grades (\n",
    "            grade_id INTEGER PRIMARY KEY,\n",
    "            subject TEXT NOT NULL,\n",
    "            grade INTEGER,\n",
    "            student_id INTEGER,\n",
    "            FOREIGN KEY (student_id) REFERENCES students (student_id)\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "# Function to insert data into tables\n",
    "def insert_data(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"INSERT INTO students (student_id, name, age) VALUES (1, 'John Doe', 20)\")\n",
    "    cursor.execute(\"INSERT INTO grades (grade_id, subject, grade, student_id) VALUES (1, 'Math', 90, 1)\")\n",
    "\n",
    "    # Commit the data insertion\n",
    "    conn.commit()\n",
    "\n",
    "# Function to print the contents of tables\n",
    "def print_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Print the \"students\" table\n",
    "    cursor.execute(\"SELECT * FROM students\")\n",
    "    print(\"\\nStudents Table:\")\n",
    "    print(cursor.fetchall())\n",
    "\n",
    "    # Print the \"grades\" table\n",
    "    cursor.execute(\"SELECT * FROM grades\")\n",
    "    print(\"\\nGrades Table:\")\n",
    "    print(cursor.fetchall())\n",
    "\n",
    "# Connect to the SQLite database (or create a new one if not exists)\n",
    "db_file_path = \"school_database.db\"\n",
    "conn = sqlite3.connect(db_file_path)\n",
    "\n",
    "create_tables(conn)\n",
    "insert_data(conn)\n",
    "print_tables(conn)\n",
    "\n",
    "# Close the database file\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9bead",
   "metadata": {},
   "source": [
    "### Exercise 5 - Data Serialization\n",
    "Create a random multidimensional array and then serialize and deserialize the array, using Pickle library.\n",
    "\n",
    "* pickle.dump(object, file) â€“ Serializes an object. \n",
    "    * Example: pickle.dump(data, open(\"data.pkl\", \"wb\")) \n",
    "* pickle.load(file) â€“ Deserializes an object. \n",
    "    * Example: data = pickle.load(open(\"data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895644a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array:\n",
      "[[0.37454012 0.95071431 0.73199394]\n",
      " [0.59865848 0.15601864 0.15599452]\n",
      " [0.05808361 0.86617615 0.60111501]]\n",
      "Serialized successfully\n",
      "Deserialized Array:\n",
      "[[0.37454012 0.95071431 0.73199394]\n",
      " [0.59865848 0.15601864 0.15599452]\n",
      " [0.05808361 0.86617615 0.60111501]]\n",
      "\n",
      "Arrays are equal: True\n"
     ]
    }
   ],
   "source": [
    "#%% 5- serialize and deserialize a randomly created array\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Define a seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to create a random NumPy array\n",
    "def create_random_array(shape):\n",
    "    return np.random.random(shape)\n",
    "\n",
    "# Function to serialize and deserialize the NumPy array using pickle\n",
    "def serialize_and_deserialize(array):\n",
    "    # Serialize the array\n",
    "    with open('serialized_array.pkl', 'wb') as file:\n",
    "        pickle.dump(array, file)\n",
    "    print(\"Serialized successfully\")\n",
    "\n",
    "    # Deserialize the array\n",
    "    with open('serialized_array.pkl', 'rb') as file:\n",
    "        loaded_array = pickle.load(file)\n",
    "\n",
    "    print(\"Deserialized Array:\")\n",
    "    print(loaded_array)\n",
    "    return loaded_array\n",
    "\n",
    "\n",
    "# Create a random NumPy array\n",
    "random_array = create_random_array((3, 3))\n",
    "\n",
    "# Print the original array\n",
    "print(\"Original Array:\")\n",
    "print(random_array)\n",
    "\n",
    "# Serialize and deserialize the array\n",
    "restored_array = serialize_and_deserialize(random_array)\n",
    "\n",
    "# Optional check\n",
    "print(\"\\nArrays are equal:\", np.array_equal(random_array, restored_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
